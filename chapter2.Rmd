# R Studio Exercise 2: Regression and model validation

*November 11, 2019*  
*This week I have performed a data wrangling on a dataset, analyzed and interpreted my regression model and did some nice plots.*

### **Looking at the dataset**  

Reading a file and attaching the needed libraries (dplyr gives some little error but works fine):  
```{r}
setwd("~/IODS-project/data")
library(ggplot2)
library("dplyr")
library(GGally)
my_learning <- read.table("learning2014.csv")
```
Exploring structure and dimensions:  
```{r}
str(my_learning)
```
We have numeric variables (deep = deep learning, stra = strategic learning, surf = surface learning), 3 integer variables (points, age, attitude) and 1 factor variable (gender).  
Lets also look at dimensions:  
```{r}
dim(my_learning)
```
The dataset has 166 observations and 7 variables. 

### **Graphs**  

Attitude and Points coloured by gender:  
```{r}
ggplot(my_learning, aes(x = Attitude, y = Points, col = gender)) +
  geom_point()
```

Summaries of variables: 
```{r}
summary(my_learning)
```
We have twice more males than females.  

Distribution of other variables:  
**Age**  
```{r}
hist(my_learning$Age, xlab = "Age", main = "Distribution of Age")
```

Distribution of age is not normal.  

**Attitude**
```{r}
hist(my_learning$Attitude, xlab = "Attitude", main = "Distribution of Attitude")
```

Distribution of attitude is normal.  

**Deep learning**
```{r}
hist(my_learning$deep, xlab = "Deep learning", main = "Distribution of Deep learning")
```

Distribution of deep learning is normal.  

**Strategic learning**
```{r}
hist(my_learning$stra, xlab = "Strategic learning", main = "Distribution of Strategic learning")
```

Distribution of strategic learning is not normal.  

**Surface learning**
```{r}
hist(my_learning$surf, xlab = "Surface learning", main = "Distribution of Surface learning")
```

Distribution of surface learning is normal.  

**Points**
```{r}
hist(my_learning$Points, xlab = "Points", main = "Distribution of Points")
```

Distribution of points is normal.  

Now lets see relationship between variables:   
```{r}
ggpairs(my_learning, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
```

**Conclusion on variables**: correlation is actually very low for all variables, but the highest is for attitude&points.    

### **Regression model**

Now I do multiple regression model with attutude, strategic questions and deep learning questions; exam points is a dependent variable:  
```{r}
model <- lm(Points ~ Attitude + stra + deep, data = my_learning)
```

Summary of the model:  
```{r}
summary(model)
```

Interpretation of model results and stats:  
1. P value is very low, which means that, at least, one of the predictor variables is significantly related to the outcome variable;  
2. Only attitude can explain points well, that is, **changes in attitude will affect points**.  

As others are not significating, we can remove them from the model:  
```{r}
modelnostranodeep <- lm(Points ~ Attitude, data = my_learning)
summary(modelnostranodeep)
```

**Conclusion**: the best model is the last one (it minimizes the prediction errors = residuals). 

I am going back to the original model:  
```{r}
model <- lm(Points ~ Attitude + stra + deep, data = my_learning)
summary(model)
```

Relationship between variables and the target: only changes in attitude affect the exam points.  
**R = 0.2097, which means that only 20% of of the variance in the points can be explained by chosen variables.**

### **Model plots**  

So our model is:  
```{r}
model <- lm(Points ~ Attitude + stra + deep, data = my_learning)
```

First, plot of **Residuals vs Fitted Values**: used to explore whether errors depend on explanatory variables:  
```{r}
plot(model, which = c(1))
```

Result: our plot looks reasonable.  

Second, **Normal QQplot**: used to explore whether the errors are normally distributed:  
```{r}
plot(model, which = c(2))
```

Result: our QQplot looks reasonable.  

Third, plot of **Residuals vs Leverage**: identifies which observations have unusually high impact on the model:  
```{r}
plot(model, which = c(5))
```

Result: our plot looks bad: there is an outlier and leverage is high.  

**Conclusion: we should remove outliers.**  

